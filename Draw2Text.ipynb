{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments Drawing -> Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea: We want to draw something and then have a neural net reconstruct the code that generated the picture. To make it more interesting, we assume that drawing takes time. This turns it into an n:m translation problem. In fact it should become a \"reverse graphics\" problem. Now the question is, can we find a big hammer that \"just learns\" given some noisy and ambiguous input, or do we need a carefully crafted model?\n",
    "\n",
    "We also want to explore the generative story: Given a part of the input, can the NN fill in the blanks - predict the future etc.\n",
    "\n",
    "This is supposed to be a simple simulation experiment - in real life, for example we want to describe what's happening in a street scene in a context of 20-30 seconds, with 3D objects and different actors doing things.\n",
    "\n",
    "Some things I want to look into:\n",
    "- \"classic\" MT models like Bahdanau et al's.\n",
    "- transformers\n",
    "- DRAW\n",
    "- generative models\n",
    "- look at program generation perhaps\n",
    "- Lecuns paper(s) on prediction\n",
    "- combinations - can we have a single model that can do both translation and generation?\n",
    "\n",
    "Also perhaps some other things I would like to get more experience on.\n",
    "- pytorch. I have surprisingly little (in fact almost no) practical experience with it since most work has been done by people on my team. Especially how to deal with minibatched sequences (masks?)\n",
    "- fast.ai\n",
    "- looking into the model to understand more what the parts are doing.\n",
    "\n",
    "We want to start with a minimal set of things to draw. My initial thought was to use Turtle - the part of the Logo language that deals with drawing things. But hooking a full logo interpreter in seems to be overkill. The main advantage of that would be that it would already have a LISP-like textual representation (see e.g. [here](https://www.calormen.com/jslogo/#).\n",
    "\n",
    "So what be the most minimal version we could do? I would say\n",
    "\n",
    "- let's start with \"setpos\" and \"forward\"\n",
    "- let's not even bother with 2D - start with 1D first\n",
    "\n",
    "Now this will of course constrain the problem a bit too much since there aren't even too many ways to present training data - the model might just memorize all combinations. But if it can't do even that it might not be worth to look further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "We first set up a small system that can interpret drawing commands and turn them into primitive animations. We're using a super simple LISP dialect that enables us to a) use expressions in that language as our desired output, b) actually execute them and c) make sure we can later expand our language without much work. \n",
    "\n",
    "We use Peter Norvigs article on \"LISP in Python\" (http://norvig.com/lispy.html) since it contains a LISP interpreter in a few lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Symbol = str              # A Scheme Symbol is implemented as a Python str\n",
    "Number = (int, float)     # A Scheme Number is implemented as a Python int or float\n",
    "Atom   = (Symbol, Number) # A Scheme Atom is a Symbol or Number\n",
    "List   = list             # A Scheme List is implemented as a Python list\n",
    "Exp    = (Atom, List)     # A Scheme expression is an Atom or List\n",
    "def tokenize(chars: str) -> list:\n",
    "    \"Convert a string of characters into a list of tokens.\"\n",
    "    return chars.replace('(', ' ( ').replace(')', ' ) ').split()\n",
    "def parse(program: str) -> Exp:\n",
    "    \"Read a Scheme expression from a string.\"\n",
    "    return read_from_tokens(tokenize(program))\n",
    "\n",
    "def read_from_tokens(tokens: list) -> Exp:\n",
    "    \"Read an expression from a sequence of tokens.\"\n",
    "    if len(tokens) == 0:\n",
    "        raise SyntaxError('unexpected EOF')\n",
    "    token = tokens.pop(0)\n",
    "    if token == '(':\n",
    "        L = []\n",
    "        while tokens[0] != ')':\n",
    "            L.append(read_from_tokens(tokens))\n",
    "        tokens.pop(0) # pop off ')'\n",
    "        return L\n",
    "    elif token == ')':\n",
    "        raise SyntaxError('unexpected )')\n",
    "    else:\n",
    "        return atom(token)\n",
    "\n",
    "def atom(token: str) -> Atom:\n",
    "    \"Numbers become numbers; every other token is a symbol.\"\n",
    "    try: return int(token)\n",
    "    except ValueError:\n",
    "        try: return float(token)\n",
    "        except ValueError:\n",
    "            return Symbol(token)\n",
    "import math\n",
    "import operator as op\n",
    "\n",
    "def standard_env():\n",
    "    \"An environment with some Scheme standard procedures.\"\n",
    "    env = {}\n",
    "    env.update(vars(math)) # sin, cos, sqrt, pi, ...\n",
    "    env.update({\n",
    "        '+':op.add, '-':op.sub, '*':op.mul, '/':op.truediv, \n",
    "        '>':op.gt, '<':op.lt, '>=':op.ge, '<=':op.le, '=':op.eq, \n",
    "        'abs':     abs,\n",
    "        'append':  op.add,  \n",
    "        'apply':   lambda proc, args: proc(*args),\n",
    "        'begin':   lambda *x: x[-1],\n",
    "        'car':     lambda x: x[0],\n",
    "        'cdr':     lambda x: x[1:], \n",
    "        'cons':    lambda x,y: [x] + y,\n",
    "        'eq?':     op.is_, \n",
    "        'equal?':  op.eq, \n",
    "        'length':  len, \n",
    "        'list':    lambda *x: list(x), \n",
    "        'list?':   lambda x: isinstance(x,list), \n",
    "        'map':     lambda *args: list(map(*args)),\n",
    "        'max':     max,\n",
    "        'min':     min,\n",
    "        'not':     op.not_,\n",
    "        'null?':   lambda x: x == [], \n",
    "        'number?': lambda x: isinstance(x, Number),   \n",
    "        'procedure?': callable,\n",
    "        'round':   round,\n",
    "        'symbol?': lambda x: isinstance(x, Symbol),\n",
    "    })\n",
    "    return env\n",
    "\n",
    "global_env = standard_env()\n",
    "def eval(x: Exp, env=global_env) -> Exp:\n",
    "    \"Evaluate an expression in an environment.\"\n",
    "    if isinstance(x, Symbol):        # variable reference\n",
    "        return env[x]\n",
    "    elif isinstance(x, Number):      # constant number\n",
    "        return x                \n",
    "    elif x[0] == 'if':               # conditional\n",
    "        (_, test, conseq, alt) = x\n",
    "        exp = (conseq if eval(test, env) else alt)\n",
    "        return eval(exp, env)\n",
    "    elif x[0] == 'define':           # definition\n",
    "        (_, symbol, exp) = x\n",
    "        env[symbol] = eval(exp, env)\n",
    "    else:                            # procedure call\n",
    "        proc = eval(x[0], env)\n",
    "        args = [eval(arg, env) for arg in x[1:]]\n",
    "        return proc(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(', 'begin', '(', 'define', 'r', '10', ')', '(', '*', 'pi', '(', '*', 'r', 'r', ')', ')', ')']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "314.1592653589793"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test it!\n",
    "x = \"(begin (define r 10) (* pi (* r r)))\"\n",
    "print(tokenize(x))\n",
    "eval(parse(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ We will try to predict streams of tokens like the above\n",
    "# Drawing functions\n",
    "So let's introduce a few primitives that allow us to draw. Stick to the most primitive version first - 1D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = []\n",
    "h, w = (1, 64)\n",
    "p = np.array([0, w//2])\n",
    "d = np.array([0,1]) # direction vector\n",
    "def clear():\n",
    "    seq = []\n",
    "def curr(): \n",
    "    global seq\n",
    "    return seq[-1]\n",
    "def new_mat():\n",
    "    global seq, h, w\n",
    "    if len(seq) > 0:\n",
    "        seq.append(np.copy(curr())) \n",
    "    else:\n",
    "        seq.append(np.zeros((h,w)))\n",
    "    return curr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearscreen():\n",
    "    global seq\n",
    "    clear()\n",
    "    print(\"clearscreen\")\n",
    "    return seq\n",
    "def fwd(x):\n",
    "    global seq, p, d\n",
    "    print(\"forward %d\" % x)\n",
    "    for i in range(x):\n",
    "        p += d\n",
    "        new_mat()[p[0],p[1]] = 1\n",
    "    return seq\n",
    "def setpos(x):\n",
    "    global p, seq\n",
    "    p = (0,x)\n",
    "    print(\"setpos %d %d\" % (0, x))\n",
    "    return seq \n",
    "\n",
    "global_env.update({\n",
    "    'forward': fwd,\n",
    "    'setpos': setpos\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setpos 0 10\n",
      "forward 10\n"
     ]
    }
   ],
   "source": [
    "x = eval(parse(\"(begin (setpos 10) (forward 10))\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "Let's make sure we can introspect the small videos as we introduce them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_anim(seq):\n",
    "  # First set up the figure, the axis, and the plot element we want to animate\n",
    "  fig, ax = plt.subplots()\n",
    "  # initialization function: plot the background of each frame\n",
    "  def init():\n",
    "    line.set_data([], [])\n",
    "    return (line,)\n",
    "\n",
    "  ax.set_xlim((0, w))\n",
    "  ax.set_ylim((0, h))\n",
    "\n",
    "  line, = ax.plot([], [], lw=2)\n",
    "  \n",
    "  def animate(i):\n",
    "    img = ax.imshow(np.concatenate((seq[i], seq[i], seq[i])))\n",
    "    return (img,)\n",
    "  anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=len(seq), interval=20, blit=True)\n",
    "  return HTML(anim.to_html5_video())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"432\" height=\"288\" controls autoplay loop>\n",
       "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAHGZ0eXBNNFYgAAACAGlzb21pc28yYXZjMQAAAAhmcmVlAAAISm1kYXQAAAKuBgX//6rcRem9\n",
       "5tlIt5Ys2CDZI+7veDI2NCAtIGNvcmUgMTU1IHIyOTE3IDBhODRkOTggLSBILjI2NC9NUEVHLTQg\n",
       "QVZDIGNvZGVjIC0gQ29weWxlZnQgMjAwMy0yMDE4IC0gaHR0cDovL3d3dy52aWRlb2xhbi5vcmcv\n",
       "eDI2NC5odG1sIC0gb3B0aW9uczogY2FiYWM9MSByZWY9MyBkZWJsb2NrPTE6MDowIGFuYWx5c2U9\n",
       "MHgzOjB4MTEzIG1lPWhleCBzdWJtZT03IHBzeT0xIHBzeV9yZD0xLjAwOjAuMDAgbWl4ZWRfcmVm\n",
       "PTEgbWVfcmFuZ2U9MTYgY2hyb21hX21lPTEgdHJlbGxpcz0xIDh4OGRjdD0xIGNxbT0wIGRlYWR6\n",
       "b25lPTIxLDExIGZhc3RfcHNraXA9MSBjaHJvbWFfcXBfb2Zmc2V0PS0yIHRocmVhZHM9OSBsb29r\n",
       "YWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFj\n",
       "ZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJh\n",
       "bWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdl\n",
       "aWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVz\n",
       "aD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBx\n",
       "cG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAAQxZYiE\n",
       "AC///vau/MsrRwuVLh1Ze7NR8uhJcv2IMH1oAAADAADVaeUGUpNWI76AABygAG/LI311tgbZfCwH\n",
       "3fzAD+/aMFz9q7twz0o2KS0+O0UqpiKqkfjEbzAQOFexUiMUzRfOyiPlXR3AIWSRKCdLe726cypy\n",
       "8RwhRwtY9+uwSaSEX9iNvDCfFdNOvyqoAwax8lEVaGME5DF1M6e+NEoNBIVvw8GY7YDXb2iviIBs\n",
       "+LuT7y4Hxn8BdLch6lM9vKe4wQ6OPvYmf2JCQS14Nk30/4krQQLUfzm0fm1LCvS9GfYiz6Cr6Ocr\n",
       "OYbKpa/TJ/q4/biojikhdv4WD+25Vs4+PGLnxnM5Rf3/8KnDKQbbvFdkXNJmNquJx7fMCinQL4cf\n",
       "P1nUM+OZ/t3ETXIQiojzPfbovkwIWFyri1Z+ENhDzGqA7OogRTA/CI48R5m2DwAIMna0GctUjlOA\n",
       "3fRB1PaVP4D0RKTiszuSi7RC2NzcO/fhYe3ucOl0hmM2KvK0MRPDh2mm+jj9L0rCoaj8wLM3RV6P\n",
       "GxM1ibe1VLy1jQiKX3cM2zXpMpvnZXLQ+TLytncnPG/aMH1PIeNrVjARb+u5rpc/bmfLPCPJvppb\n",
       "CKdxgiQT/3PPH7+8kxdcvNsNyMAyI3Teiz8U/oNXbNn5u1QjDCFse+XLKuxy/JLN8KLlkAQ2DkSP\n",
       "Ka5BhbTsOyJk8GtVKF48x5qFxXhH11CM01Lu8Y5ShgHPKN4DLtTjanWGzjbTmQo+U3Oz4Xhz3cEq\n",
       "JZe2u1EHOOKk6+IKQVTVkvcQ6Q6Tn9LSi6+QAtwv3gKcr4sWuilS1ZOnnn+gNNcFpOYb4VzPB0du\n",
       "U3SY7GM78prUqKk1yrY62Fm4Bo3fk/FolEOf83YFIYYgTRvK9O1wSbWc349iHTwk8EgcFVP0tNDG\n",
       "urd213iTq3yn6kk7jqTLkNw+wti8sO3tEt5aPbVIXBNzjwnjcb134LvkT1iu8kR4JfXLxaJZzPi3\n",
       "c1VfRAzi6hS5r3/vX68qZv6PNwOtIlCKOiiDAbfdKGZ9QxS/l6mb9g9rVo8tQEK3iV2tO8/VfF0F\n",
       "mQmZ6vchJ2oii4LqbC2uoRLhT+2Ul6se15ZOV299zRR/2rnatGr2chMJWnwY1PWSOvU53IF6xKjt\n",
       "rw5foFipsjZ4V1B4/Sfv1hYjjHHBWPLm173lWLOb/JRG0D8sf4wMJBxKFr7dWwQPOt1D7g3ezlE4\n",
       "nTRkqStzCMk1setBGH3eWeIMKnoNaTupV2+F7BF8cN2h4h/aL8aTQ9bPlw16gStHgrZWXEVBMBH+\n",
       "fMilTSJfqbJ3m8h/gdo/L24hhMybIUpstlB/eAF+xeHspLj2rlgnvxXH0aD+1BA0KlH7KvzaxXN4\n",
       "dRwyaceXrnDcIlvFDDVR0Ru5Dc5MYBvrwHlI+AAAAwAAAwAAAwAAAwAACNkAAABTQZojbEK//jhA\n",
       "AF/1VywcUUKA9DxEjYFVB8jEPMRdhJ1CEgMl6ISrcjUabdDusvx58BZ7Z5a/3UCZn9YOkZ2Wb1iL\n",
       "PdiuiepZ5pc2CwNfFu4altAAAAAWQZ5BeIR/AAetT6UzZlKsqO4Fj8HqgQAAABMBnmJqR/8ADGks\n",
       "o0W/I8vStsDAAAAAGUGaZUmoQWiZTBTwr/44QABc43vj+EvgVfEAAAASAZ6Eakf/AAwaDGlH0QvL\n",
       "kg8xAAAARUGaiUnhClJlMCP//IQABY/Y3ebNkoAIfc0/9Od7qsX7kyjBkNpb5IQpYsCPyKE0M+cN\n",
       "UIA3Uk0DzN0BP0pmmmPUepzNSQAAABlBnqdFNEwj/wAHl/1F5WhCqACdNio/PkuBAAAAEQGexnRH\n",
       "/wAMPgiNH2O9XBqmAAAAIQGeyGpH/wALySyjReaXsAAhm4vV4Ssmhisbhom4GiyVbAAAA55tb292\n",
       "AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPoAAAAyAABAAABAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAA\n",
       "AAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAACyHRy\n",
       "YWsAAABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAAAAAAyAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAA\n",
       "AAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAABsAAAASAAAAAAACRlZHRzAAAAHGVsc3QAAAAA\n",
       "AAAAAQAAAMgAAAIAAAEAAAAAAkBtZGlhAAAAIG1kaGQAAAAAAAAAAAAAAAAAADIAAAAKAFXEAAAA\n",
       "AAAtaGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAAAFZpZGVvSGFuZGxlcgAAAAHrbWluZgAAABR2\n",
       "bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJlZgAAAAAAAAABAAAADHVybCAAAAABAAABq3N0\n",
       "YmwAAACzc3RzZAAAAAAAAAABAAAAo2F2YzEAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAABsAEgAEgA\n",
       "AABIAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY//8AAAAxYXZjQwFk\n",
       "AB7/4QAYZ2QAHqzZQbCWhAAAAwAEAAADAZA8WLZYAQAGaOvjyyLAAAAAHHV1aWRraEDyXyRPxbo5\n",
       "pRvPAyPzAAAAAAAAABhzdHRzAAAAAAAAAAEAAAAKAAABAAAAABRzdHNzAAAAAAAAAAEAAAABAAAA\n",
       "WGN0dHMAAAAAAAAACQAAAAEAAAIAAAAAAQAABAAAAAACAAABAAAAAAEAAAMAAAAAAQAAAQAAAAAB\n",
       "AAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAABxzdHNjAAAAAAAAAAEAAAABAAAACgAAAAEA\n",
       "AAA8c3RzegAAAAAAAAAAAAAACgAABucAAABXAAAAGgAAABcAAAAdAAAAFgAAAEkAAAAdAAAAFQAA\n",
       "ACUAAAAUc3RjbwAAAAAAAAABAAAALAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAA\n",
       "AG1kaXJhcHBsAAAAAAAAAAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTgu\n",
       "MjAuMTAw\n",
       "\">\n",
       "  Your browser does not support the video tag.\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_anim(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ how do I get rid of the last output?\n",
    "# The first Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
